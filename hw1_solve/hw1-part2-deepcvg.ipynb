{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"homework_optimization.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Knowledge distillation\nSuppose that we have a large network (*teacher network*) or an ensemble of networks which has a good accuracy but doesn't fit into memory/runtime requirements. Instead of training a smaller network (*student network*) directly on the original dataset, we can train this network to predict outputs of teacher networks. It turns out that the perfomance could be even better! This approach doesn't help with training speed, but can be quite beneficial when we'd like to reduce the model size for low-memory devices.\n\n* https://www.ttic.edu/dl/dark14.pdf\n* [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)\n* https://medium.com/neural-machines/knowledge-distillation-dc241d7c2322\n\nEven the completely different ([article](https://arxiv.org/abs/1711.10433)) architecture can be used in a student model, e.g. you can approximate an autoregressive model (WaveNet) by a non-autoregressive one.","metadata":{"colab_type":"text","id":"fXad1svpSk8f"}},{"cell_type":"markdown","source":"# Task\n## 1. Teacher network\nTrain good enough (teacher) network, achieve >=35% accuracy on validation set of Tiny Imagenet (you can reuse any network from homework part 1 here).","metadata":{}},{"cell_type":"code","source":"!wget --no-check-certificate 'https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img.py' -O tiny_img.py\n!wget --no-check-certificate 'https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img_dataset.py' -O tiny_img_dataset.py","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:31:48.501177Z","iopub.execute_input":"2024-03-11T13:31:48.501887Z","iopub.status.idle":"2024-03-11T13:31:50.959995Z","shell.execute_reply.started":"2024-03-11T13:31:48.501841Z","shell.execute_reply":"2024-03-11T13:31:50.958766Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2024-03-11 13:31:49--  https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 813 [text/plain]\nSaving to: 'tiny_img.py'\n\ntiny_img.py         100%[===================>]     813  --.-KB/s    in 0s      \n\n2024-03-11 13:31:49 (39.1 MB/s) - 'tiny_img.py' saved [813/813]\n\n--2024-03-11 13:31:50--  https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img_dataset.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1555 (1.5K) [text/plain]\nSaving to: 'tiny_img_dataset.py'\n\ntiny_img_dataset.py 100%[===================>]   1.52K  --.-KB/s    in 0s      \n\n2024-03-11 13:31:50 (25.4 MB/s) - 'tiny_img_dataset.py' saved [1555/1555]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from tiny_img import download_tinyImg200\ndata_path = '.'\ndownload_tinyImg200(data_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:32:26.265636Z","iopub.execute_input":"2024-03-11T13:32:26.266361Z","iopub.status.idle":"2024-03-11T13:33:19.707901Z","shell.execute_reply.started":"2024-03-11T13:32:26.266324Z","shell.execute_reply":"2024-03-11T13:33:19.706856Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Dataset was downloaded to './tiny-imagenet-200.zip'\nExtract downloaded dataset to '.'\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms\nimport tqdm\n\ndef get_computing_device():\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n    else:\n        device = torch.device('cpu')\n    return device\n\ndevice = get_computing_device()\nprint(f\"Our main computing device is '{device}'\")","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:33:24.294480Z","iopub.execute_input":"2024-03-11T13:33:24.294880Z","iopub.status.idle":"2024-03-11T13:33:29.375157Z","shell.execute_reply.started":"2024-03-11T13:33:24.294851Z","shell.execute_reply":"2024-03-11T13:33:29.374189Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Our main computing device is 'cuda:0'\n","output_type":"stream"}]},{"cell_type":"code","source":"train_trainsforms = transforms.Compose(\n    [transforms.RandomHorizontalFlip(),\n     transforms.ToTensor(),\n     transforms.RandomRotation(5),\n     torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:33:40.346566Z","iopub.execute_input":"2024-03-11T13:33:40.347475Z","iopub.status.idle":"2024-03-11T13:33:40.352260Z","shell.execute_reply.started":"2024-03-11T13:33:40.347443Z","shell.execute_reply":"2024-03-11T13:33:40.351392Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tiny_img_dataset\ntrain_dataset = tiny_img_dataset.TinyImagenetRAM('tiny-imagenet-200/train', transform=train_trainsforms)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:33:41.212592Z","iopub.execute_input":"2024-03-11T13:33:41.213421Z","iopub.status.idle":"2024-03-11T13:35:15.192376Z","shell.execute_reply.started":"2024-03-11T13:33:41.213390Z","shell.execute_reply":"2024-03-11T13:35:15.191540Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"tiny-imagenet-200/train: 100%|██████████| 200/200 [01:33<00:00,  2.14it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport os\nfrom PIL import Image\n\nclass TinyImagenetValDataset(Dataset):\n    def __init__(self, root, transform=transforms.ToTensor()):\n        super().__init__()\n\n        self.root = root\n        with open(os.path.join(root, 'val_annotations.txt')) as f:\n            annotations = []\n            for line in f:\n                img_name, class_label = line.split('\\t')[:2]\n                annotations.append((img_name, class_label))\n\n        self.classes = sorted(list(set(annotation[1] for annotation in annotations)))\n\n        assert len(self.classes) == 200, len(self.classes)\n        assert all(self.classes[i] < self.classes[i+1] for i in range(len(self.classes)-1)), 'classes should be ordered'\n        assert all(isinstance(elem, type(annotations[0][1])) for elem in self.classes), 'your just need to reuse class_labels'\n\n        self.class_to_idx = {item: index for index, item in enumerate(self.classes)}\n\n        self.transform = transform\n\n        self.images, self.targets = [], []\n        for img_name, class_name in tqdm.tqdm(annotations, desc=root):\n            img_name = os.path.join(root, 'images', img_name)\n            # 3. load image and store it in self.images (your may want to use tiny_img_dataset.read_rgb_image)\n            # store the class index in self.targets\n            image = tiny_img_dataset.read_rgb_image(img_name)\n\n            assert image.shape == (64, 64, 3), image.shape\n            self.images.append(Image.fromarray(image))\n            self.targets.append(self.class_to_idx[class_name])\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, index):\n        # take image and its target label from \"self.images\" and \"self.targets\",\n        # transform the image using self.transform and return the transformed image and its target label\n\n        image = self.images[index]\n        image = self.transform(image)\n        target = self.targets[index]\n\n        return image, target","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:35:16.429110Z","iopub.execute_input":"2024-03-11T13:35:16.429972Z","iopub.status.idle":"2024-03-11T13:35:16.442705Z","shell.execute_reply.started":"2024-03-11T13:35:16.429940Z","shell.execute_reply":"2024-03-11T13:35:16.441798Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"val_dataset = TinyImagenetValDataset('tiny-imagenet-200/val', transform=transforms.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:35:18.636105Z","iopub.execute_input":"2024-03-11T13:35:18.636748Z","iopub.status.idle":"2024-03-11T13:35:28.069514Z","shell.execute_reply.started":"2024-03-11T13:35:18.636711Z","shell.execute_reply":"2024-03-11T13:35:28.068615Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"tiny-imagenet-200/val: 100%|██████████| 10000/10000 [00:09<00:00, 1062.47it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 64\ntrain_batch_gen = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=12)\nval_batch_gen = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False, num_workers=12)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:35:33.727083Z","iopub.execute_input":"2024-03-11T13:35:33.727937Z","iopub.status.idle":"2024-03-11T13:35:33.736041Z","shell.execute_reply.started":"2024-03-11T13:35:33.727903Z","shell.execute_reply":"2024-03-11T13:35:33.735062Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch, torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\ndef compute_loss(y_pred, y_true):\n    return F.cross_entropy(y_pred, y_true).mean()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:35:38.734810Z","iopub.execute_input":"2024-03-11T13:35:38.735165Z","iopub.status.idle":"2024-03-11T13:35:38.740896Z","shell.execute_reply.started":"2024-03-11T13:35:38.735137Z","shell.execute_reply":"2024-03-11T13:35:38.739820Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class GlobalAveragePooling(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n        \n    def forward(self, x):\n        return torch.mean(x, dim=self.dim)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:35:40.566574Z","iopub.execute_input":"2024-03-11T13:35:40.566922Z","iopub.status.idle":"2024-03-11T13:35:40.572247Z","shell.execute_reply.started":"2024-03-11T13:35:40.566893Z","shell.execute_reply":"2024-03-11T13:35:40.571317Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class ConvBNRelu(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super().__init__() \n        \n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        return self.relu(self.bn(self.conv(x)))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:35:41.482704Z","iopub.execute_input":"2024-03-11T13:35:41.483059Z","iopub.status.idle":"2024-03-11T13:35:41.489320Z","shell.execute_reply.started":"2024-03-11T13:35:41.483029Z","shell.execute_reply":"2024-03-11T13:35:41.488275Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, 1, padding)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.relu2 = nn.ReLU()\n        \n        self.conv3 = None\n        if in_channels != out_channels or stride != 1:\n            self.conv3 = nn.Conv2d(in_channels, out_channels, 1, stride, 0)\n        \n    def forward(self, x):\n        residual = self.bn2(self.conv2(self.relu1(self.bn1(self.conv1(x)))))\n        \n        if self.conv3 is not None:\n            x = self.conv3(x)\n        \n        return self.relu2(x + residual)        \n    \n    \ndef create_network_like_resnet():\n    model = nn.Sequential()\n    config = [[32, 32], [64, 64], [128, 128]]\n    \n    model.add_module(\"init_conv\", ConvBNRelu(3, 32, kernel_size=7, stride=2, padding=3)) \n    in_channels = 32\n    for i in range(len(config)):\n        for j in range(len(config[i])):\n            out_channels = config[i][j]\n            stride = 2 if i != 0 and j == 0 else 1\n            model.add_module(f\"ResidualBlock{i}_{j}\", ResidualBlock(in_channels, out_channels, 3, stride, padding=1))\n            in_channels = out_channels\n            \n    model.add_module(\"pool\", GlobalAveragePooling((2, 3)))\n    model.add_module(\"logits\", nn.Linear(out_channels, 200))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:35:46.266481Z","iopub.execute_input":"2024-03-11T13:35:46.267117Z","iopub.status.idle":"2024-03-11T13:35:46.279232Z","shell.execute_reply.started":"2024-03-11T13:35:46.267084Z","shell.execute_reply":"2024-03-11T13:35:46.278271Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport time\n\ndef eval_model(model, val_batch_gen):\n    model.train(False) \n    val_accuracy = []\n    with torch.no_grad():\n        for X_batch, y_batch in val_batch_gen:\n            X_batch = X_batch.to(device)\n            logits = model(X_batch)\n            y_pred = logits.max(1)[1].data\n            val_accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n            \n    return np.mean(val_accuracy)\n\n\ndef train_model(model, opt, train_batch_gen):\n    model.train(True) \n    train_loss = []\n    for (X_batch, y_batch) in tqdm.tqdm(train_batch_gen):\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n        opt.zero_grad()\n        predictions = model(X_batch) \n        loss = compute_loss(predictions, y_batch)\n        loss.backward()\n        opt.step()\n        \n        train_loss.append(loss.cpu().data.numpy())\n        \n    return np.mean(train_loss)\n\n\ndef train_loop(model, opt, train_data_generator, val_data_generator, num_epochs):\n    for epoch in range(num_epochs):\n        start_time = time.time()\n\n        train_loss = train_model(model, opt, train_data_generator)\n\n        val_accuracy = eval_model(model, val_data_generator)\n\n        # Then we print the results for this epoch:\n        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:35:47.401811Z","iopub.execute_input":"2024-03-11T13:35:47.402457Z","iopub.status.idle":"2024-03-11T13:35:47.413454Z","shell.execute_reply.started":"2024-03-11T13:35:47.402426Z","shell.execute_reply":"2024-03-11T13:35:47.412567Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = create_network_like_resnet().to(device)\nopt = torch.optim.Adam(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:40:25.439921Z","iopub.execute_input":"2024-03-11T14:40:25.440300Z","iopub.status.idle":"2024-03-11T14:40:25.525544Z","shell.execute_reply.started":"2024-03-11T14:40:25.440268Z","shell.execute_reply":"2024-03-11T14:40:25.524551Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_loop(model, opt, train_batch_gen, val_batch_gen, 30)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:40:27.546224Z","iopub.execute_input":"2024-03-11T14:40:27.547087Z","iopub.status.idle":"2024-03-11T15:42:08.202330Z","shell.execute_reply.started":"2024-03-11T14:40:27.547050Z","shell.execute_reply":"2024-03-11T15:42:08.201050Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"  0%|          | 0/1563 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n100%|██████████| 1563/1563 [02:00<00:00, 13.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 of 30 took 122.109s\n  training loss (in-iteration): \t4.714720\n  validation accuracy: \t\t\t8.18 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:00<00:00, 13.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 of 30 took 122.236s\n  training loss (in-iteration): \t3.955818\n  validation accuracy: \t\t\t18.77 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 of 30 took 123.448s\n  training loss (in-iteration): \t3.240875\n  validation accuracy: \t\t\t26.09 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:00<00:00, 12.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 of 30 took 122.713s\n  training loss (in-iteration): \t3.030022\n  validation accuracy: \t\t\t30.73 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:58<00:00, 13.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 of 30 took 120.716s\n  training loss (in-iteration): \t2.863729\n  validation accuracy: \t\t\t33.36 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:58<00:00, 13.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 of 30 took 120.528s\n  training loss (in-iteration): \t2.730980\n  validation accuracy: \t\t\t34.79 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:58<00:00, 13.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 of 30 took 120.500s\n  training loss (in-iteration): \t2.618864\n  validation accuracy: \t\t\t36.50 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:00<00:00, 12.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 of 30 took 122.860s\n  training loss (in-iteration): \t2.520372\n  validation accuracy: \t\t\t37.96 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 of 30 took 123.045s\n  training loss (in-iteration): \t2.444409\n  validation accuracy: \t\t\t38.35 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:59<00:00, 13.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 of 30 took 121.982s\n  training loss (in-iteration): \t2.369544\n  validation accuracy: \t\t\t40.19 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 of 30 took 123.733s\n  training loss (in-iteration): \t2.308589\n  validation accuracy: \t\t\t39.22 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 of 30 took 123.803s\n  training loss (in-iteration): \t2.254659\n  validation accuracy: \t\t\t41.71 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 of 30 took 123.307s\n  training loss (in-iteration): \t2.196541\n  validation accuracy: \t\t\t40.89 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 of 30 took 123.386s\n  training loss (in-iteration): \t2.147367\n  validation accuracy: \t\t\t43.09 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 of 30 took 123.931s\n  training loss (in-iteration): \t2.104187\n  validation accuracy: \t\t\t42.30 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 of 30 took 123.933s\n  training loss (in-iteration): \t2.061252\n  validation accuracy: \t\t\t42.51 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 of 30 took 123.463s\n  training loss (in-iteration): \t2.025293\n  validation accuracy: \t\t\t43.41 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 of 30 took 123.410s\n  training loss (in-iteration): \t1.988471\n  validation accuracy: \t\t\t43.41 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:02<00:00, 12.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 of 30 took 124.915s\n  training loss (in-iteration): \t1.954000\n  validation accuracy: \t\t\t43.16 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:03<00:00, 12.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 of 30 took 125.135s\n  training loss (in-iteration): \t1.918566\n  validation accuracy: \t\t\t42.62 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 of 30 took 123.443s\n  training loss (in-iteration): \t1.889911\n  validation accuracy: \t\t\t42.71 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 of 30 took 123.511s\n  training loss (in-iteration): \t1.856441\n  validation accuracy: \t\t\t43.88 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 of 30 took 123.675s\n  training loss (in-iteration): \t1.832178\n  validation accuracy: \t\t\t44.28 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:02<00:00, 12.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 of 30 took 124.355s\n  training loss (in-iteration): \t1.804302\n  validation accuracy: \t\t\t43.96 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:03<00:00, 12.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 of 30 took 125.839s\n  training loss (in-iteration): \t1.779635\n  validation accuracy: \t\t\t44.34 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:02<00:00, 12.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 of 30 took 124.490s\n  training loss (in-iteration): \t1.744399\n  validation accuracy: \t\t\t44.60 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:02<00:00, 12.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 of 30 took 124.837s\n  training loss (in-iteration): \t1.731961\n  validation accuracy: \t\t\t44.53 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:01<00:00, 12.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 of 30 took 123.727s\n  training loss (in-iteration): \t1.704812\n  validation accuracy: \t\t\t44.76 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [02:03<00:00, 12.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 of 30 took 125.027s\n  training loss (in-iteration): \t1.682346\n  validation accuracy: \t\t\t44.72 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Student network \nTrain small (student) network, achieve 20-25% accuracy, draw a plot \"training and testing errors vs train step index\"","metadata":{}},{"cell_type":"code","source":"def create_student_network():\n    \n    model = nn.Sequential()\n    model.add_module(\"conv1\", ConvBNRelu(3, 32, 7, 2, 3))\n    model.add_module(\"max_pool\", nn.MaxPool2d(3, stride=2))\n    model.add_module(\"conv2\", ConvBNRelu(32, 64, 3, 2, 1))\n    model.add_module(\"pool\", GlobalAveragePooling((2, 3)))\n    model.add_module(\"fc\", nn.Linear(64, 128))\n    model.add_module(\"relu\", nn.ReLU())\n    model.add_module(\"logits\", nn.Linear(128, 200))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-11T19:07:22.164957Z","iopub.execute_input":"2024-03-11T19:07:22.165372Z","iopub.status.idle":"2024-03-11T19:07:22.172723Z","shell.execute_reply.started":"2024-03-11T19:07:22.165337Z","shell.execute_reply":"2024-03-11T19:07:22.171816Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"student_model = create_student_network().to(device)\noptimizer = torch.optim.Adam(student_model.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-03-11T19:07:22.968971Z","iopub.execute_input":"2024-03-11T19:07:22.969331Z","iopub.status.idle":"2024-03-11T19:07:22.977610Z","shell.execute_reply.started":"2024-03-11T19:07:22.969302Z","shell.execute_reply":"2024-03-11T19:07:22.976737Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train_loop(student_model, optimizer, train_batch_gen, val_batch_gen, 30)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T19:07:23.855769Z","iopub.execute_input":"2024-03-11T19:07:23.856124Z","iopub.status.idle":"2024-03-11T20:05:57.240985Z","shell.execute_reply.started":"2024-03-11T19:07:23.856097Z","shell.execute_reply":"2024-03-11T20:05:57.239713Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"100%|██████████| 1563/1563 [01:57<00:00, 13.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 of 30 took 118.810s\n  training loss (in-iteration): \t4.708207\n  validation accuracy: \t\t\t6.60 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 of 30 took 116.828s\n  training loss (in-iteration): \t4.326375\n  validation accuracy: \t\t\t7.04 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 of 30 took 116.861s\n  training loss (in-iteration): \t4.168486\n  validation accuracy: \t\t\t9.60 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 of 30 took 116.014s\n  training loss (in-iteration): \t4.059654\n  validation accuracy: \t\t\t10.41 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 of 30 took 116.101s\n  training loss (in-iteration): \t3.968739\n  validation accuracy: \t\t\t12.39 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 of 30 took 117.360s\n  training loss (in-iteration): \t3.897012\n  validation accuracy: \t\t\t13.78 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 of 30 took 117.276s\n  training loss (in-iteration): \t3.841599\n  validation accuracy: \t\t\t16.36 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 of 30 took 116.704s\n  training loss (in-iteration): \t3.789825\n  validation accuracy: \t\t\t15.85 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 of 30 took 117.609s\n  training loss (in-iteration): \t3.751338\n  validation accuracy: \t\t\t15.50 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 of 30 took 117.335s\n  training loss (in-iteration): \t3.711197\n  validation accuracy: \t\t\t16.45 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 of 30 took 116.195s\n  training loss (in-iteration): \t3.676489\n  validation accuracy: \t\t\t15.35 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 of 30 took 117.599s\n  training loss (in-iteration): \t3.654718\n  validation accuracy: \t\t\t18.38 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 of 30 took 116.663s\n  training loss (in-iteration): \t3.621308\n  validation accuracy: \t\t\t20.22 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:56<00:00, 13.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 of 30 took 117.740s\n  training loss (in-iteration): \t3.597739\n  validation accuracy: \t\t\t13.90 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:56<00:00, 13.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 of 30 took 118.196s\n  training loss (in-iteration): \t3.572458\n  validation accuracy: \t\t\t18.61 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 of 30 took 117.272s\n  training loss (in-iteration): \t3.555182\n  validation accuracy: \t\t\t17.54 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:56<00:00, 13.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 of 30 took 118.459s\n  training loss (in-iteration): \t3.528723\n  validation accuracy: \t\t\t20.33 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 of 30 took 117.276s\n  training loss (in-iteration): \t3.511779\n  validation accuracy: \t\t\t19.31 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 of 30 took 116.911s\n  training loss (in-iteration): \t3.497319\n  validation accuracy: \t\t\t20.36 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 of 30 took 117.036s\n  training loss (in-iteration): \t3.479439\n  validation accuracy: \t\t\t19.93 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:56<00:00, 13.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 of 30 took 118.094s\n  training loss (in-iteration): \t3.464734\n  validation accuracy: \t\t\t17.29 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:56<00:00, 13.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 of 30 took 118.457s\n  training loss (in-iteration): \t3.450871\n  validation accuracy: \t\t\t16.39 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:53<00:00, 13.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 of 30 took 114.908s\n  training loss (in-iteration): \t3.439452\n  validation accuracy: \t\t\t20.18 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 of 30 took 116.101s\n  training loss (in-iteration): \t3.424638\n  validation accuracy: \t\t\t19.54 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 of 30 took 116.040s\n  training loss (in-iteration): \t3.417302\n  validation accuracy: \t\t\t22.12 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 of 30 took 116.513s\n  training loss (in-iteration): \t3.404962\n  validation accuracy: \t\t\t22.35 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:52<00:00, 13.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 of 30 took 114.556s\n  training loss (in-iteration): \t3.392428\n  validation accuracy: \t\t\t22.66 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 of 30 took 116.044s\n  training loss (in-iteration): \t3.379768\n  validation accuracy: \t\t\t20.41 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 of 30 took 117.239s\n  training loss (in-iteration): \t3.367305\n  validation accuracy: \t\t\t21.42 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:59<00:00, 13.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 of 30 took 121.177s\n  training loss (in-iteration): \t3.356396\n  validation accuracy: \t\t\t21.39 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. Knowledge distillation\n![image info](https://miro.medium.com/max/875/1*WxFiH3XDY1-28tbyi4BGDA.png)\n\nAt this block you will have to retrain your student network using \"knowledge distillation\" technique. **Distill teacher network with student network, achieve at least +1% improvement in accuracy over student network accuracy.**\n\nThe training procedure is the same as for training the student network from scratch except the loss formulation.\n\nAssume that \n- $z_i$ are logits predicted by the student network at the current step for an input image\n- $v_i$ are logits predicted by the (freezed) teacher network\n- $y_i$ are one-hot encoded label of the input image\n- $p_i = \\frac{\\exp{z_i}}{\\sum_j \\exp{z_j}}$ - logits $z_i$ after sofrmax\n- $q_i = \\frac{\\exp{\\frac{z_i}{T}}}{\\sum_j \\exp{\\frac{z_j}{T}}}$, where $T$ is softmax temperature\n- $r_i = \\frac{\\exp{\\frac{v_i}{T}}}{\\sum_j \\exp{\\frac{v_j}{T}}}$, where $T$ is the same softmax temperature as for $q_i$\n\nThe loss for knowledge distillation: $$-\\sum_i y_i \\log p_i - \\alpha \\sum_i r_i \\log q_i$$\n\n$T$ and $\\alpha$ are hyperparameters. \n\n- There is a good practice of using softmax with high temperature to obtain \"soft\" distributions, you can start with $T=10$. Check the [post](https://medium.com/mlearning-ai/softmax-temperature-5492e4007f71) with good visualizations on how the temperature affects the softmax output. \n- For $\\alpha$ there is the following note in the original [paper](https://arxiv.org/pdf/1503.02531.pdf):\n\n> Since the magnitudes of the gradients produced by the soft targets scale as $1/T^2$ it is important to multiply them by $T^2$ when using both hard and soft targets. This ensures that the relative contributions of the hard and soft targets remain roughly unchanged if the temperature used for distillation is changed while experimenting with meta-parameters.","metadata":{}},{"cell_type":"code","source":"model = model.train(False)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:06:44.329066Z","iopub.execute_input":"2024-03-11T21:06:44.329454Z","iopub.status.idle":"2024-03-11T21:06:44.334672Z","shell.execute_reply.started":"2024-03-11T21:06:44.329424Z","shell.execute_reply":"2024-03-11T21:06:44.333771Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"student_model = create_student_network().to(device)\noptimizer = torch.optim.Adam(student_model.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:06:45.031611Z","iopub.execute_input":"2024-03-11T21:06:45.031984Z","iopub.status.idle":"2024-03-11T21:06:45.040830Z","shell.execute_reply.started":"2024-03-11T21:06:45.031954Z","shell.execute_reply":"2024-03-11T21:06:45.039912Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"def distillation_train_model(student_model, teacher_model, optimizer, train_batch_gen, T, alpha):\n    student_model.train(True) \n    train_loss = []\n    for (X_batch, y_batch) in tqdm.tqdm(train_batch_gen):\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        \n        student_predictions = student_model(X_batch)\n        teacher_predictions = teacher_model(X_batch)\n        \n        student_loss = compute_loss(student_predictions, y_batch)\n        distillation_loss = compute_loss(student_predictions / T, F.softmax(teacher_predictions / T, dim=-1))\n        \n        loss = student_loss + alpha * distillation_loss\n        loss.backward()\n        optimizer.step()\n        \n        train_loss.append(loss.cpu().data.numpy())\n        \n    return np.mean(train_loss)\n\ndef distillation_train_loop(student_model, teacher_model, optimizer, train_data_generator, val_data_generator, T, alpha, num_epochs):\n    for epoch in range(num_epochs):\n        start_time = time.time()\n\n        train_loss = distillation_train_model(student_model, teacher_model, optimizer, train_data_generator, T, alpha)\n\n        val_accuracy = eval_model(student_model, val_data_generator)\n\n        # Then we print the results for this epoch:\n        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:09:47.430254Z","iopub.execute_input":"2024-03-11T21:09:47.430963Z","iopub.status.idle":"2024-03-11T21:09:47.441657Z","shell.execute_reply.started":"2024-03-11T21:09:47.430933Z","shell.execute_reply":"2024-03-11T21:09:47.440727Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# проверку на early stoping надо будет в будущем подключить и графики train loss и val accuracy прикрутить\nT = 10 # 2\nalpha = 100 # 4\ndistillation_train_loop(student_model, model, optimizer, train_batch_gen, val_batch_gen, T, alpha, 30)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:09:55.033769Z","iopub.execute_input":"2024-03-11T21:09:55.034505Z","iopub.status.idle":"2024-03-11T22:08:16.801078Z","shell.execute_reply.started":"2024-03-11T21:09:55.034464Z","shell.execute_reply":"2024-03-11T22:08:16.799821Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 of 30 took 115.883s\n  training loss (in-iteration): \t531.717834\n  validation accuracy: \t\t\t5.10 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 of 30 took 116.895s\n  training loss (in-iteration): \t530.391968\n  validation accuracy: \t\t\t9.20 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 of 30 took 117.515s\n  training loss (in-iteration): \t529.865417\n  validation accuracy: \t\t\t10.63 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 of 30 took 116.245s\n  training loss (in-iteration): \t529.517578\n  validation accuracy: \t\t\t12.37 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 of 30 took 116.233s\n  training loss (in-iteration): \t529.269531\n  validation accuracy: \t\t\t14.36 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 of 30 took 116.380s\n  training loss (in-iteration): \t529.085266\n  validation accuracy: \t\t\t12.40 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 of 30 took 116.644s\n  training loss (in-iteration): \t528.924500\n  validation accuracy: \t\t\t11.89 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 of 30 took 117.586s\n  training loss (in-iteration): \t528.804688\n  validation accuracy: \t\t\t12.68 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 of 30 took 116.749s\n  training loss (in-iteration): \t528.677551\n  validation accuracy: \t\t\t16.52 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 of 30 took 117.054s\n  training loss (in-iteration): \t528.594177\n  validation accuracy: \t\t\t18.68 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 of 30 took 117.130s\n  training loss (in-iteration): \t528.522400\n  validation accuracy: \t\t\t18.73 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 of 30 took 116.878s\n  training loss (in-iteration): \t528.453125\n  validation accuracy: \t\t\t18.07 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 of 30 took 116.774s\n  training loss (in-iteration): \t528.373657\n  validation accuracy: \t\t\t13.03 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 of 30 took 116.829s\n  training loss (in-iteration): \t528.320374\n  validation accuracy: \t\t\t18.10 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 of 30 took 116.470s\n  training loss (in-iteration): \t528.255737\n  validation accuracy: \t\t\t18.04 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:56<00:00, 13.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 of 30 took 118.012s\n  training loss (in-iteration): \t528.224304\n  validation accuracy: \t\t\t20.54 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:56<00:00, 13.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 of 30 took 117.872s\n  training loss (in-iteration): \t528.180420\n  validation accuracy: \t\t\t19.50 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:56<00:00, 13.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 of 30 took 118.597s\n  training loss (in-iteration): \t528.116821\n  validation accuracy: \t\t\t20.40 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 of 30 took 117.497s\n  training loss (in-iteration): \t528.096436\n  validation accuracy: \t\t\t22.27 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 of 30 took 116.662s\n  training loss (in-iteration): \t528.053284\n  validation accuracy: \t\t\t19.82 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 of 30 took 116.838s\n  training loss (in-iteration): \t528.020935\n  validation accuracy: \t\t\t19.95 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:53<00:00, 13.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 of 30 took 114.749s\n  training loss (in-iteration): \t527.986389\n  validation accuracy: \t\t\t20.49 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 of 30 took 116.728s\n  training loss (in-iteration): \t527.955444\n  validation accuracy: \t\t\t22.84 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:53<00:00, 13.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 of 30 took 115.382s\n  training loss (in-iteration): \t527.922974\n  validation accuracy: \t\t\t21.36 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:53<00:00, 13.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 of 30 took 115.192s\n  training loss (in-iteration): \t527.908081\n  validation accuracy: \t\t\t23.81 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:52<00:00, 13.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 of 30 took 114.359s\n  training loss (in-iteration): \t527.888672\n  validation accuracy: \t\t\t22.12 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:53<00:00, 13.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 of 30 took 114.762s\n  training loss (in-iteration): \t527.852905\n  validation accuracy: \t\t\t21.28 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:54<00:00, 13.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 of 30 took 116.464s\n  training loss (in-iteration): \t527.838867\n  validation accuracy: \t\t\t20.68 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:58<00:00, 13.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 of 30 took 120.473s\n  training loss (in-iteration): \t527.820190\n  validation accuracy: \t\t\t23.08 %\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [01:55<00:00, 13.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 of 30 took 116.904s\n  training loss (in-iteration): \t527.803955\n  validation accuracy: \t\t\t21.96 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Final notes**:\n- Please, don't cheat with early-early-early stopping while training of the student network. Make sure, it  converged.\n- Logits still carry more information than the probabilities after softmax.\n- Don't forget to use your teacher network in 'eval' mode. And don't forget your main objective.\n\n**Future readings**\n- [\"Born again neural networks\"](https://arxiv.org/pdf/1805.04770.pdf) - knowledge distillation may give benefits even when teacher and student networks have the same architecture.\n- [\"Prune your model before distill it\"](https://arxiv.org/pdf/2109.14960.pdf) - pruning of the teacher model before distillation may improve quality of student model","metadata":{}}]}