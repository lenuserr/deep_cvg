Lecture slides - __[click here](https://yadi.sk/i/M_5pn6-EYxjf3Q)__

__Note__: Seminars assume that you remember batch normalization and dropout from last lecture. If you don't, go recap week2.


## Materials
- [russian] Convolutional networks - [video](https://yadi.sk/i/hDIkaR4H3EtnXM)
- [english] Convolutional networks (karpathy) - [video](https://www.youtube.com/watch?v=AQirPKrAyDg)

- Reading
  - http://cs231n.github.io/convolutional-networks/
  - http://cs231n.github.io/understanding-cnn/
  - [a deep learning neophite cheat sheet](http://www.kdnuggets.com/2016/03/must-know-tips-deep-learning-part-1.html)
  - [more stuff for vision](https://bavm2013.splashthat.com/img/events/46439/assets/34a7.ranzato.pdf)
  - a [CNN trainer in a browser](https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html)
  
- Bonus reading:
  - Interpreting neural network predictions: [distill.pub post](https://distill.pub/2018/building-blocks/)


## Practice

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yandexdataschool/deep_vision_and_graphics/blob/fall22/week02-convnets/seminar_pytorch.ipynb)
